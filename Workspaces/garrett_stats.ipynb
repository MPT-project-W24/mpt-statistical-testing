{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e998af-c82a-494f-bde4-735f4003cc9f",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3bdcc7-f67e-40bb-990d-33fbfc3697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from os import listdir, getcwd, chdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c7469-ccd0-43f5-9a21-fb1ccd435715",
   "metadata": {},
   "source": [
    "Load selected data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb513a9f-eaca-44f0-886b-95b176131cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the all file names from the data directory/folder\n",
    "features_data_path = \"/home/gmcp/mpt-statistical-testing/features_data/\"\n",
    "feature_files = [f for f in listdir(features_data_path) if isfile(join(features_data_path, f)) and '.csv' in f and \"P\" in f]\n",
    "#print(len(feature_files))\n",
    "#print(feature_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7610041-9e96-4cf2-b85a-53bba82a5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .csv files into dictionary\n",
    "def read_feature_files(files_list, pathname):\n",
    "    \"\"\"\n",
    "    Quick function to read in .csv data files.\n",
    "    Does not have functionality currently to raise error \n",
    "    if a file does not exist in the path.\n",
    "    Option to use \n",
    "\n",
    "    Args:\n",
    "        files_list : list of str\n",
    "            list of strings of .csv file names\n",
    "        pathname : str\n",
    "            file path to folder or directory that contains the desired .csv files\n",
    "\n",
    "    Output: \n",
    "        features_dataframes : dict\n",
    "            dictionary of pandas dataframes\n",
    "    \"\"\"\n",
    "    features_dataframes = {}\n",
    "    for file in files_list:\n",
    "        features_dataframes[file] = pd.read_csv(pathname+file,index_col=0)\n",
    "    return features_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6398ae9e-730a-4df9-8672-b031c4787c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = read_feature_files(feature_files, features_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5017bf-627a-4493-8b41-0ef15c397196",
   "metadata": {},
   "source": [
    "Functions to do pairwise Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "755c8530-bc7c-4e43-817c-553a89a27f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise Pearson correlation\n",
    "def corr_rowi_rowj(row_i, row_j):\n",
    "    \"\"\"\n",
    "    Pearson correlation between row_i and row_j\n",
    "\n",
    "    Args: \n",
    "        row_i, row_j : pd.Series\n",
    "            row of data from dataframe, represented as a pandas series\n",
    "\n",
    "    Output: \n",
    "        corr_ij : float\n",
    "            Pearson correlation of row_i to row_j\n",
    "    \"\"\"\n",
    "    if row_i.any() == False or row_j.any() == False:\n",
    "        raise Exception(\"A row is all zeros and does not work with .corr\")\n",
    "    corr_ij = row_i.corr(row_j)\n",
    "    return corr_ij\n",
    "    \n",
    "\n",
    "def corr_rowi_vs_all(row_i, dataframe):\n",
    "    \"\"\"\n",
    "    Vector of Pearson correlations for each row against row_i\n",
    "\n",
    "    Args: \n",
    "        row_i : pd.Series\n",
    "            row of data from dataframe, represented as a pandas series\n",
    "        dataframe : pd.DataFrame\n",
    "            dataframe containing data of interest\n",
    "    \n",
    "    Output:\n",
    "        corr_to_i : list\n",
    "            list of Pearson correlation values stored as float values\n",
    "    \"\"\"\n",
    "    corr_to_i = []\n",
    "    for j, row_j in dataframe.iterrows():\n",
    "        corr_to_i.append(corr_rowi_rowj(row_i,row_j))\n",
    "    return corr_to_i\n",
    "     \n",
    "def pairwise_correlation(dataframe):\n",
    "    \"\"\"\n",
    "    Pairwise Pearson correlation of all rows, plus conversion back to dataframe.\n",
    "    If issues arise, might need to transpose dataframe.\n",
    "\n",
    "    Args: \n",
    "        dataframe : pd.DataFrame\n",
    "            dataframe containing data of interest\n",
    "    \n",
    "    Output: \n",
    "        corr_df = pd.DataFrame\n",
    "            pandas dataframe containing all pairwise Pearson correlation values\n",
    "    \"\"\" \n",
    "    corr_all = []\n",
    "    for i, row_i in dataframe.iterrows():\n",
    "        corr_all.append( corr_rowi_vs_all(row_i, dataframe) )\n",
    "    corr_df = pd.DataFrame(\n",
    "        np.array(corr_all), # corr_all needs to convert to Numpy array from list\n",
    "        index=dataframe.index,\n",
    "        columns=dataframe.index)\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176104a8-5f1f-475b-9a38-3448fce039a6",
   "metadata": {},
   "source": [
    "Function to pull descriptive statistics from one or more features of a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9478a672-b760-4575-baec-c557edf85e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs descriptive statistics on specified features in a dataframe\n",
    "def feature_descriptive_statistics(dataframe, features):\n",
    "    \"\"\"\n",
    "    This function pulls the descriptive statistics from given features. Input the features as a list of str.\n",
    "    Can use \"all_features\" to run descriptive statistics on all features without needing to make a long list of names.\n",
    "    Quantiles are disabled automatically. To use, make separate variables for each desired quantile and append.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        dataframe : pd.DataFrame\n",
    "            dataframe containing data of interest\n",
    "        features : list of str, or str\n",
    "            list of strings which are the features stored as column names in the data frame.\n",
    "            can use \"all_features\" to run all feature columns\n",
    "    \n",
    "    Output: \n",
    "        feat_descriptive_statistics_df : pd.DataFrame\n",
    "            Pandas dataframe of the descriptive statistics as columns and features as rows\n",
    "    \"\"\"\n",
    "    feat_descriptive_statistics = []\n",
    "    if features == \"all_features\":\n",
    "        features = dataframe.columns.tolist()\n",
    "        # need to add method to remove Unnamed:0 and ID\n",
    "        for feature in features:\n",
    "            feat_stats = []\n",
    "            feat_mean = dataframe[feature].mean();feat_stats.append(feat_mean)\n",
    "            feat_median = dataframe[feature].median();feat_stats.append(feat_median)\n",
    "            feat_max = dataframe[feature].max();feat_stats.append(feat_max)\n",
    "            feat_min = dataframe[feature].min();feat_stats.append(feat_min)\n",
    "            #feat_quantile1, feat_quantile2 = dataframe[feature].quantile([0.25, 0.75])\n",
    "            #feat_stats.append(feat_quantile1,feat_quantile2)\n",
    "            feat_var = dataframe[feature].var();feat_stats.append(feat_var)\n",
    "            feat_std = dataframe[feature].std();feat_stats.append(feat_std)\n",
    "            feat_descriptive_statistics.append(feat_stats)\n",
    "    else:\n",
    "        for feature in features:\n",
    "            feat_stats = []\n",
    "            feat_mean = dataframe[feature].mean();feat_stats.append(feat_mean)\n",
    "            feat_median = dataframe[feature].median();feat_stats.append(feat_median)\n",
    "            feat_max = dataframe[feature].max();feat_stats.append(feat_max)\n",
    "            feat_min = dataframe[feature].min();feat_stats.append(feat_min)\n",
    "            #feat_quantiles = dataframe[feature].quantile([0.25, 0.75])\n",
    "            #feat_stats.append(feat_quantiles)\n",
    "            feat_var = dataframe[feature].var();feat_stats.append(feat_var)\n",
    "            feat_std = dataframe[feature].std();feat_stats.append(feat_std)\n",
    "            feat_descriptive_statistics.append(feat_stats)\n",
    "    stat_names = [\"mean\", \"median\", \"maximum\", \"minimum\",\n",
    "                  \"variance\", \"standard deviation\"] \n",
    "    feat_descriptive_statistics_df = pd.DataFrame(\n",
    "        np.array(feat_descriptive_statistics),\n",
    "        index=features,\n",
    "        columns=stat_names)\n",
    "    return feat_descriptive_statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205a246a-bf80-4448-abad-1db106e5e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>D_fit</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>asymmetry1</th>\n",
       "      <th>asymmetry2</th>\n",
       "      <th>asymmetry3</th>\n",
       "      <th>AR</th>\n",
       "      <th>elongation</th>\n",
       "      <th>boundedness</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean convex_hull</th>\n",
       "      <th>Std convex_hull</th>\n",
       "      <th>Mean convex_hull_norm</th>\n",
       "      <th>Std convex_hull_norm</th>\n",
       "      <th>Mean dist_tot</th>\n",
       "      <th>Std dist_tot</th>\n",
       "      <th>Mean dist_net</th>\n",
       "      <th>Std dist_net</th>\n",
       "      <th>Mean progression</th>\n",
       "      <th>Std progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.044580</td>\n",
       "      <td>111.125959</td>\n",
       "      <td>2.019197</td>\n",
       "      <td>0.617458</td>\n",
       "      <td>0.346346</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>1.935849</td>\n",
       "      <td>0.483431</td>\n",
       "      <td>0.095876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23410.038597</td>\n",
       "      <td>8060.004574</td>\n",
       "      <td>2010.932948</td>\n",
       "      <td>64.207167</td>\n",
       "      <td>0.094711</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.159148</td>\n",
       "      <td>10.766955</td>\n",
       "      <td>1.870196</td>\n",
       "      <td>0.993848</td>\n",
       "      <td>0.039279</td>\n",
       "      <td>0.557336</td>\n",
       "      <td>3.764191</td>\n",
       "      <td>0.734339</td>\n",
       "      <td>0.044533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37120.132308</td>\n",
       "      <td>11975.092611</td>\n",
       "      <td>2322.137756</td>\n",
       "      <td>40.500374</td>\n",
       "      <td>0.069408</td>\n",
       "      <td>0.022246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.271617</td>\n",
       "      <td>8.371443</td>\n",
       "      <td>1.597442</td>\n",
       "      <td>0.404523</td>\n",
       "      <td>0.471676</td>\n",
       "      <td>0.066609</td>\n",
       "      <td>1.977858</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>0.053624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37120.132308</td>\n",
       "      <td>11975.092611</td>\n",
       "      <td>2322.137756</td>\n",
       "      <td>40.500374</td>\n",
       "      <td>0.069408</td>\n",
       "      <td>0.022246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.009474</td>\n",
       "      <td>2.820423</td>\n",
       "      <td>2.949629</td>\n",
       "      <td>0.682320</td>\n",
       "      <td>0.308665</td>\n",
       "      <td>0.150285</td>\n",
       "      <td>1.922496</td>\n",
       "      <td>0.479843</td>\n",
       "      <td>0.157116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22176.252529</td>\n",
       "      <td>4087.478085</td>\n",
       "      <td>1786.963066</td>\n",
       "      <td>71.774691</td>\n",
       "      <td>0.083388</td>\n",
       "      <td>0.015486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.545154</td>\n",
       "      <td>5.008628</td>\n",
       "      <td>5.088765</td>\n",
       "      <td>0.988937</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.518906</td>\n",
       "      <td>2.839301</td>\n",
       "      <td>0.647801</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45170.218915</td>\n",
       "      <td>29786.417000</td>\n",
       "      <td>2144.765566</td>\n",
       "      <td>84.918362</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.025918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.316939</td>\n",
       "      <td>85.800203</td>\n",
       "      <td>3.112588</td>\n",
       "      <td>0.680587</td>\n",
       "      <td>0.309684</td>\n",
       "      <td>0.149556</td>\n",
       "      <td>2.193355</td>\n",
       "      <td>0.544078</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25775.270384</td>\n",
       "      <td>4500.622689</td>\n",
       "      <td>2175.050937</td>\n",
       "      <td>84.154787</td>\n",
       "      <td>0.086276</td>\n",
       "      <td>0.011273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.361029</td>\n",
       "      <td>45.228190</td>\n",
       "      <td>2.359616</td>\n",
       "      <td>0.938111</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>0.357796</td>\n",
       "      <td>2.430197</td>\n",
       "      <td>0.588511</td>\n",
       "      <td>0.089951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42333.631822</td>\n",
       "      <td>17200.589004</td>\n",
       "      <td>2472.800011</td>\n",
       "      <td>55.418964</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.026378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.800348</td>\n",
       "      <td>34.189379</td>\n",
       "      <td>2.740176</td>\n",
       "      <td>0.403265</td>\n",
       "      <td>0.472460</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>1.625616</td>\n",
       "      <td>0.384848</td>\n",
       "      <td>0.169429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25775.270384</td>\n",
       "      <td>4500.622689</td>\n",
       "      <td>2175.050937</td>\n",
       "      <td>84.154787</td>\n",
       "      <td>0.086276</td>\n",
       "      <td>0.011273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.338518</td>\n",
       "      <td>127.447869</td>\n",
       "      <td>2.602074</td>\n",
       "      <td>0.511113</td>\n",
       "      <td>0.407718</td>\n",
       "      <td>0.092675</td>\n",
       "      <td>1.566647</td>\n",
       "      <td>0.361694</td>\n",
       "      <td>0.047617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45170.218915</td>\n",
       "      <td>29786.417000</td>\n",
       "      <td>2144.765566</td>\n",
       "      <td>84.918362</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>0.025918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.027666</td>\n",
       "      <td>28.139240</td>\n",
       "      <td>3.733755</td>\n",
       "      <td>0.883781</td>\n",
       "      <td>0.175718</td>\n",
       "      <td>0.282048</td>\n",
       "      <td>2.369166</td>\n",
       "      <td>0.577911</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25775.270384</td>\n",
       "      <td>4500.622689</td>\n",
       "      <td>2175.050937</td>\n",
       "      <td>84.154787</td>\n",
       "      <td>0.086276</td>\n",
       "      <td>0.011273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Track_ID     alpha       D_fit  kurtosis  asymmetry1  asymmetry2  \\\n",
       "10      10.0  0.044580  111.125959  2.019197    0.617458    0.346346   \n",
       "11      11.0  1.159148   10.766955  1.870196    0.993848    0.039279   \n",
       "12      12.0  1.271617    8.371443  1.597442    0.404523    0.471676   \n",
       "13      13.0  2.009474    2.820423  2.949629    0.682320    0.308665   \n",
       "14      14.0  1.545154    5.008628  5.088765    0.988937    0.052737   \n",
       "15      15.0  0.316939   85.800203  3.112588    0.680587    0.309684   \n",
       "16      16.0  0.361029   45.228190  2.359616    0.938111    0.126374   \n",
       "17      17.0  0.800348   34.189379  2.740176    0.403265    0.472460   \n",
       "18      18.0  0.338518  127.447869  2.602074    0.511113    0.407718   \n",
       "19      19.0  1.027666   28.139240  3.733755    0.883781    0.175718   \n",
       "\n",
       "    asymmetry3        AR  elongation  boundedness  ...  Mean convex_hull  \\\n",
       "10    0.125400  1.935849    0.483431     0.095876  ...               0.0   \n",
       "11    0.557336  3.764191    0.734339     0.044533  ...               0.0   \n",
       "12    0.066609  1.977858    0.494403     0.053624  ...               0.0   \n",
       "13    0.150285  1.922496    0.479843     0.157116  ...               0.0   \n",
       "14    0.518906  2.839301    0.647801     0.047887  ...               0.0   \n",
       "15    0.149556  2.193355    0.544078     0.143137  ...               0.0   \n",
       "16    0.357796  2.430197    0.588511     0.089951  ...               0.0   \n",
       "17    0.066331  1.625616    0.384848     0.169429  ...               0.0   \n",
       "18    0.092675  1.566647    0.361694     0.047617  ...               0.0   \n",
       "19    0.282048  2.369166    0.577911     0.052379  ...               0.0   \n",
       "\n",
       "    Std convex_hull  Mean convex_hull_norm  Std convex_hull_norm  \\\n",
       "10              0.0                    0.0                   0.0   \n",
       "11              0.0                    0.0                   0.0   \n",
       "12              0.0                    0.0                   0.0   \n",
       "13              0.0                    0.0                   0.0   \n",
       "14              0.0                    0.0                   0.0   \n",
       "15              0.0                    0.0                   0.0   \n",
       "16              0.0                    0.0                   0.0   \n",
       "17              0.0                    0.0                   0.0   \n",
       "18              0.0                    0.0                   0.0   \n",
       "19              0.0                    0.0                   0.0   \n",
       "\n",
       "    Mean dist_tot  Std dist_tot  Mean dist_net  Std dist_net  \\\n",
       "10   23410.038597   8060.004574    2010.932948     64.207167   \n",
       "11   37120.132308  11975.092611    2322.137756     40.500374   \n",
       "12   37120.132308  11975.092611    2322.137756     40.500374   \n",
       "13   22176.252529   4087.478085    1786.963066     71.774691   \n",
       "14   45170.218915  29786.417000    2144.765566     84.918362   \n",
       "15   25775.270384   4500.622689    2175.050937     84.154787   \n",
       "16   42333.631822  17200.589004    2472.800011     55.418964   \n",
       "17   25775.270384   4500.622689    2175.050937     84.154787   \n",
       "18   45170.218915  29786.417000    2144.765566     84.918362   \n",
       "19   25775.270384   4500.622689    2175.050937     84.154787   \n",
       "\n",
       "    Mean progression  Std progression  \n",
       "10          0.094711         0.026536  \n",
       "11          0.069408         0.022246  \n",
       "12          0.069408         0.022246  \n",
       "13          0.083388         0.015486  \n",
       "14          0.063797         0.025918  \n",
       "15          0.086276         0.011273  \n",
       "16          0.068725         0.026378  \n",
       "17          0.086276         0.011273  \n",
       "18          0.063797         0.025918  \n",
       "19          0.086276         0.011273  \n",
       "\n",
       "[10 rows x 91 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyFeatures_df1 = pd.read_csv(\"../features_data/features_P14_40nm_s2_v2.csv\",index_col=0).iloc[10:20]\n",
    "dummyFeatures_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054f8206-359a-477c-8248-d91bc0300fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dummyFeatures_df1.iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b2cc13-9156-4c26-bd17-4df9402c3508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>variance</th>\n",
       "      <th>standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.887447</td>\n",
       "      <td>0.914007</td>\n",
       "      <td>2.009474</td>\n",
       "      <td>0.044580</td>\n",
       "      <td>0.394947</td>\n",
       "      <td>0.628448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asymmetry3</th>\n",
       "      <td>0.236694</td>\n",
       "      <td>0.149920</td>\n",
       "      <td>0.557336</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>0.184185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean    median   maximum   minimum  variance  \\\n",
       "alpha       0.887447  0.914007  2.009474  0.044580  0.394947   \n",
       "asymmetry3  0.236694  0.149920  0.557336  0.066331  0.033924   \n",
       "\n",
       "            standard deviation  \n",
       "alpha                 0.628448  \n",
       "asymmetry3            0.184185  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_descriptive_statistics(dummyFeatures_df1,[\"alpha\",\"asymmetry3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf3b878-955e-4c1e-833b-3af677951368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>variance</th>\n",
       "      <th>standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Track_ID</th>\n",
       "      <td>14.500000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.166667e+00</td>\n",
       "      <td>3.027650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.887447</td>\n",
       "      <td>0.914007</td>\n",
       "      <td>2.009474</td>\n",
       "      <td>0.044580</td>\n",
       "      <td>3.949468e-01</td>\n",
       "      <td>0.628448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_fit</th>\n",
       "      <td>45.889829</td>\n",
       "      <td>31.164309</td>\n",
       "      <td>127.447869</td>\n",
       "      <td>2.820423</td>\n",
       "      <td>2.124469e+03</td>\n",
       "      <td>46.091959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis</th>\n",
       "      <td>2.807344</td>\n",
       "      <td>2.671125</td>\n",
       "      <td>5.088765</td>\n",
       "      <td>1.597442</td>\n",
       "      <td>1.042992e+00</td>\n",
       "      <td>1.021270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asymmetry1</th>\n",
       "      <td>0.710394</td>\n",
       "      <td>0.681454</td>\n",
       "      <td>0.993848</td>\n",
       "      <td>0.403265</td>\n",
       "      <td>5.308465e-02</td>\n",
       "      <td>0.230401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std dist_tot</th>\n",
       "      <td>12637.295895</td>\n",
       "      <td>10017.548592</td>\n",
       "      <td>29786.417000</td>\n",
       "      <td>4087.478085</td>\n",
       "      <td>1.002836e+08</td>\n",
       "      <td>10014.171696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean dist_net</th>\n",
       "      <td>2172.965548</td>\n",
       "      <td>2175.050937</td>\n",
       "      <td>2472.800011</td>\n",
       "      <td>1786.963066</td>\n",
       "      <td>3.458460e+04</td>\n",
       "      <td>185.969354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std dist_net</th>\n",
       "      <td>69.470266</td>\n",
       "      <td>77.964739</td>\n",
       "      <td>84.918362</td>\n",
       "      <td>40.500374</td>\n",
       "      <td>3.370169e+02</td>\n",
       "      <td>18.358019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean progression</th>\n",
       "      <td>0.077206</td>\n",
       "      <td>0.076398</td>\n",
       "      <td>0.094711</td>\n",
       "      <td>0.063797</td>\n",
       "      <td>1.271766e-04</td>\n",
       "      <td>0.011277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std progression</th>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>0.026536</td>\n",
       "      <td>0.011273</td>\n",
       "      <td>4.580116e-05</td>\n",
       "      <td>0.006768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean        median       maximum      minimum  \\\n",
       "Track_ID             14.500000     14.500000     19.000000    10.000000   \n",
       "alpha                 0.887447      0.914007      2.009474     0.044580   \n",
       "D_fit                45.889829     31.164309    127.447869     2.820423   \n",
       "kurtosis              2.807344      2.671125      5.088765     1.597442   \n",
       "asymmetry1            0.710394      0.681454      0.993848     0.403265   \n",
       "...                        ...           ...           ...          ...   \n",
       "Std dist_tot      12637.295895  10017.548592  29786.417000  4087.478085   \n",
       "Mean dist_net      2172.965548   2175.050937   2472.800011  1786.963066   \n",
       "Std dist_net         69.470266     77.964739     84.918362    40.500374   \n",
       "Mean progression      0.077206      0.076398      0.094711     0.063797   \n",
       "Std progression       0.019855      0.022246      0.026536     0.011273   \n",
       "\n",
       "                      variance  standard deviation  \n",
       "Track_ID          9.166667e+00            3.027650  \n",
       "alpha             3.949468e-01            0.628448  \n",
       "D_fit             2.124469e+03           46.091959  \n",
       "kurtosis          1.042992e+00            1.021270  \n",
       "asymmetry1        5.308465e-02            0.230401  \n",
       "...                        ...                 ...  \n",
       "Std dist_tot      1.002836e+08        10014.171696  \n",
       "Mean dist_net     3.458460e+04          185.969354  \n",
       "Std dist_net      3.370169e+02           18.358019  \n",
       "Mean progression  1.271766e-04            0.011277  \n",
       "Std progression   4.580116e-05            0.006768  \n",
       "\n",
       "[91 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_descriptive_statistics(dummyFeatures_df1,\"all_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e308797-c208-42b0-99fd-427797dccc44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89fa0c09-6c59-4784-b13f-9f556180f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs descriptive statistics on dataframes within a dictionary \n",
    "def multi_df_feat_descriptive_statistics(dataframes, features):\n",
    "    \"\"\"\n",
    "    This function takes an input dictionary of dataframes and \n",
    "    a list of features str to automatically run multiple dataframes through\n",
    "    the feature descriptive statistics, returning a dictionary with the same keys. \n",
    "    For running statistics on all features use \"all_features\".\n",
    "\n",
    "    Args:\n",
    "        dataframes : dict\n",
    "            dictionary of dataframes containing data of interest\n",
    "        features : list of str, or str\n",
    "            list of strings which are the features stored as column names in the data frame.\n",
    "            can use \"all_features\" to run all feature columns\n",
    "\n",
    "    Output: \n",
    "        dfs_descriptive_statistics : dict\n",
    "            dictionary of dataframes containing descriptive statistics of specified features\n",
    "            utilizes the same keys as the input dataframe dictionary\n",
    "    \"\"\"\n",
    "    dfs_descriptive_statistics = {}\n",
    "    for key in dataframes:\n",
    "        dfs_descriptive_statistics[key] = feature_descriptive_statistics(dataframes[key],features)\n",
    "    return dfs_descriptive_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14038040-6f3a-465b-9d2a-f3c2080ccc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60a12522-774a-4f9c-af63-5aa956b861fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11299809-3aec-4334-bb0f-be663c48a581",
   "metadata": {},
   "source": [
    "Below is troubleshooting trying to get the comprehension to work with a dataframe to pull values in a feature column that satisfy standard deviation outlier parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21fe777-1088-4582-aa6d-12d57882fd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track_ID            float64\n",
       "alpha               float64\n",
       "D_fit               float64\n",
       "kurtosis            float64\n",
       "asymmetry1          float64\n",
       "                     ...   \n",
       "Std dist_tot        float64\n",
       "Mean dist_net       float64\n",
       "Std dist_net        float64\n",
       "Mean progression    float64\n",
       "Std progression     float64\n",
       "Length: 91, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyFeatures_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e481ce6-e4da-456d-8365-4712403705fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_mean = dummyFeatures_df1[\"alpha\"].mean()\n",
    "feat_std = dummyFeatures_df1[\"alpha\"].std()\n",
    "type(feat_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcdc0a33-84f1-4047-9064-f11dac5dac57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feat_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6319c36a-3433-4f00-bef1-37331a1e4d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.009474037293017, 1.54515378436631]\n"
     ]
    }
   ],
   "source": [
    "dummy_above = [row_i[\"alpha\"] for index, row_i in dummyFeatures_df1.iterrows() if row_i[\"alpha\"] >= feat_mean + (1 * feat_std)]\n",
    "print(dummy_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0809613f-f681-417e-baaa-5119be3e5b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914006891498764 0.899354422817235\n"
     ]
    }
   ],
   "source": [
    "feat_median = dummyFeatures_df1[\"alpha\"].median()\n",
    "feat_iqr = sp.stats.iqr(dummyFeatures_df1[\"alpha\"])\n",
    "print(feat_median,feat_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4954ea9-15c9-4f4f-aca1-ab9147793f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "outliers_above2 = [row_i[\"alpha\"] for index, row_i in dummyFeatures_df1.iterrows() if row_i[\"alpha\"] >= feat_median+(1.5*feat_iqr)]\n",
    "print(outliers_above2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c02dd98-bfa5-4eee-9f96-57a6a6ccae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulls out values of a feature that satis of std away from mean\n",
    "def feature_outliers(dataframe, features, outlier_method):\n",
    "    \"\"\"\n",
    "    Rapid calculation the outliers of specified feature data within a dataframe.\n",
    "    Has the options of STD multiplier and IQR for selecting an outlier selection parameter.\n",
    "\n",
    "    Args:\n",
    "        dataframe : pd.DataFrame\n",
    "            dataframe containing data of interest\n",
    "        features : list of str, or str\n",
    "            list of strings which are the features stored as column names in the data frame.\n",
    "            Can use \"all_features\" string to run all features.\n",
    "        outlier_method : str\n",
    "            either \"STD multiplier\" or \"IQR\" to specify method of determining outlier cutoff.\n",
    "            \"STD multiplier\" will prompt user to enter a float value to use as a multiplier\n",
    "            of the standard deviation.\n",
    "\n",
    "    Output:\n",
    "        feature_outliers_dict : dict\n",
    "            dictionary containing lists of found outliers above and below selected cutoff for\n",
    "            specified features\n",
    "    \"\"\"\n",
    "    if features == \"all_features\":\n",
    "        features = dataframe.columns.tolist()\n",
    "        if outlier_method == \"STD multiplier\":\n",
    "            n_by_std = float(input(\"Enter the multiplier you want to use:\"))\n",
    "            feature_outliers_dict = {}\n",
    "            for feature in features:\n",
    "                feat_mean = dataframe[feature].mean()\n",
    "                feat_std = dataframe[feature].std()\n",
    "                outliers_above = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] >= feat_mean+(n_by_std*feat_std)]\n",
    "                outliers_below = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] <= feat_mean-(n_by_std*feat_std)]\n",
    "                feature_outliers_dict[feature+\" outliers above\"] = outliers_above\n",
    "                feature_outliers_dict[feature+\" outliers below\"] = outliers_below\n",
    "    \n",
    "        elif outlier_method == \"IQR\":\n",
    "            feature_outliers_dict = {}\n",
    "            for feature in features:\n",
    "                feat_iqr = sp.stats.iqr(dataframe[feature])\n",
    "                feat_median = dataframe[feature].median()\n",
    "                outliers_above = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] >= feat_median+(1.5*feat_iqr)]\n",
    "                outliers_below = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] <= feat_median-(1.5*feat_iqr)]\n",
    "                feature_outliers_dict[feature+\" outliers above\"] = outliers_above\n",
    "                feature_outliers_dict[feature+\" outliers below\"] = outliers_below\n",
    "    \n",
    "    else:\n",
    "        if outlier_method == \"STD multiplier\":\n",
    "            n_by_std = float(input(\"Enter the multiplier you want to use:\"))\n",
    "            feature_outliers_dict = {}\n",
    "            for feature in features:\n",
    "                feat_mean = dataframe[feature].mean()\n",
    "                feat_std = dataframe[feature].std()\n",
    "                outliers_above = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] >= feat_mean+(n_by_std*feat_std)]\n",
    "                outliers_below = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] <= feat_mean-(n_by_std*feat_std)]\n",
    "                feature_outliers_dict[feature+\" outliers above\"] = outliers_above\n",
    "                feature_outliers_dict[feature+\" outliers below\"] = outliers_below\n",
    "    \n",
    "        elif outlier_method == \"IQR\":\n",
    "            feature_outliers_dict = {}\n",
    "            for feature in features:\n",
    "                feat_iqr = sp.stats.iqr(dataframe[feature])\n",
    "                feat_median = dataframe[feature].median()\n",
    "                outliers_above = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] >= feat_median+(1.5*feat_iqr)]\n",
    "                outliers_below = [row_i[feature] for index, row_i in dataframe.iterrows() if row_i[feature] <= feat_median-(1.5*feat_iqr)]\n",
    "                feature_outliers_dict[feature+\" outliers above\"] = outliers_above\n",
    "                feature_outliers_dict[feature+\" outliers below\"] = outliers_below\n",
    "    return feature_outliers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e03a1a-23d8-4379-a875-9f25119c0815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the multiplier you want to use: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha outliers above': [],\n",
       " 'alpha outliers below': [],\n",
       " 'kurtosis outliers above': [],\n",
       " 'kurtosis outliers below': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_outliers(dummyFeatures_df1, [\"alpha\",\"kurtosis\"], \"STD multiplier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b44591-95b5-44c0-b53f-b0cd2c0dfa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the multiplier you want to use: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha outliers above': [],\n",
       " 'alpha outliers below': [],\n",
       " 'kurtosis outliers above': [5.088764991351239],\n",
       " 'kurtosis outliers below': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_outliers(dummyFeatures_df1, [\"alpha\",\"kurtosis\"], \"STD multiplier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da53401c-91c6-4c97-a355-031cb16d5901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha outliers above': [],\n",
       " 'alpha outliers below': [],\n",
       " 'kurtosis outliers above': [5.088764991351239],\n",
       " 'kurtosis outliers below': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_outliers(dummyFeatures_df1, [\"alpha\",\"kurtosis\"], \"IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1c2c31-c6ef-4482-ad22-c41f8e6f707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Track_ID outliers above': [],\n",
       " 'Track_ID outliers below': [],\n",
       " 'alpha outliers above': [],\n",
       " 'alpha outliers below': [],\n",
       " 'D_fit outliers above': [],\n",
       " 'D_fit outliers below': [],\n",
       " 'kurtosis outliers above': [5.088764991351239],\n",
       " 'kurtosis outliers below': [],\n",
       " 'asymmetry1 outliers above': [],\n",
       " 'asymmetry1 outliers below': [],\n",
       " 'asymmetry2 outliers above': [],\n",
       " 'asymmetry2 outliers below': [],\n",
       " 'asymmetry3 outliers above': [0.5573361703399577, 0.5189056831788302],\n",
       " 'asymmetry3 outliers below': [],\n",
       " 'AR outliers above': [3.764191154993878, 2.839301412613269],\n",
       " 'AR outliers below': [],\n",
       " 'elongation outliers above': [0.7343386776005465],\n",
       " 'elongation outliers below': [],\n",
       " 'boundedness outliers above': [],\n",
       " 'boundedness outliers below': [],\n",
       " 'fractal_dim outliers above': [],\n",
       " 'fractal_dim outliers below': [],\n",
       " 'trappedness outliers above': [],\n",
       " 'trappedness outliers below': [],\n",
       " 'efficiency outliers above': [2.419955314929289],\n",
       " 'efficiency outliers below': [],\n",
       " 'straightness outliers above': [],\n",
       " 'straightness outliers below': [],\n",
       " 'MSD_ratio outliers above': [0.7388873491425489, 0.6625624671579222],\n",
       " 'MSD_ratio outliers below': [],\n",
       " 'frames outliers above': [27.0, 33.0],\n",
       " 'frames outliers below': [],\n",
       " 'X outliers above': [],\n",
       " 'X outliers below': [],\n",
       " 'Y outliers above': [],\n",
       " 'Y outliers below': [],\n",
       " 'Quality outliers above': [10.535421518163847, 10.266537006084617],\n",
       " 'Quality outliers below': [4.763866969515714, 5.675095113117667],\n",
       " 'Mean_Intensity outliers above': [],\n",
       " 'Mean_Intensity outliers below': [230.9963086009524, 230.8894056847667],\n",
       " 'SN_Ratio outliers above': [],\n",
       " 'SN_Ratio outliers below': [],\n",
       " 'Deff1 outliers above': [37.61690904255444],\n",
       " 'Deff1 outliers below': [],\n",
       " 'Deff2 outliers above': [],\n",
       " 'Deff2 outliers below': [],\n",
       " 'angle_mean outliers above': [],\n",
       " 'angle_mean outliers below': [-59.97913719440319, -64.96647700802367],\n",
       " 'angle_mag_mean outliers above': [],\n",
       " 'angle_mag_mean outliers below': [32.19365930501855],\n",
       " 'angle_var outliers above': [],\n",
       " 'angle_var outliers below': [],\n",
       " 'convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'dist_tot outliers above': [59183.81555520424, 68697.45958933394],\n",
       " 'dist_tot outliers below': [],\n",
       " 'dist_net outliers above': [],\n",
       " 'dist_net outliers below': [1917.4470470824149],\n",
       " 'progression outliers above': [],\n",
       " 'progression outliers below': [],\n",
       " 'Mean alpha outliers above': [],\n",
       " 'Mean alpha outliers below': [0.7868234484073454],\n",
       " 'Std alpha outliers above': [0.8317932871467918, 0.6060964234188484],\n",
       " 'Std alpha outliers below': [0.4219481633452205, 0.4219481633452205],\n",
       " 'Mean D_fit outliers above': [],\n",
       " 'Mean D_fit outliers below': [],\n",
       " 'Std D_fit outliers above': [],\n",
       " 'Std D_fit outliers below': [18.633333932558383],\n",
       " 'Mean kurtosis outliers above': [],\n",
       " 'Mean kurtosis outliers below': [1.9576833300239556],\n",
       " 'Std kurtosis outliers above': [],\n",
       " 'Std kurtosis outliers below': [],\n",
       " 'Mean asymmetry1 outliers above': [],\n",
       " 'Mean asymmetry1 outliers below': [0.6397322317092197, 0.6397322317092197],\n",
       " 'Std asymmetry1 outliers above': [],\n",
       " 'Std asymmetry1 outliers below': [],\n",
       " 'Mean asymmetry2 outliers above': [0.3196433831768951, 0.3196433831768951],\n",
       " 'Mean asymmetry2 outliers below': [0.1674821534222128, 0.1674821534222128],\n",
       " 'Std asymmetry2 outliers above': [0.2940350651670775],\n",
       " 'Std asymmetry2 outliers below': [],\n",
       " 'Mean asymmetry3 outliers above': [],\n",
       " 'Mean asymmetry3 outliers below': [],\n",
       " 'Std asymmetry3 outliers above': [0.2482284502576809],\n",
       " 'Std asymmetry3 outliers below': [],\n",
       " 'Mean AR outliers above': [3.390230159654572],\n",
       " 'Mean AR outliers below': [1.795587045847908],\n",
       " 'Std AR outliers above': [2.3585166656791228],\n",
       " 'Std AR outliers below': [],\n",
       " 'Mean elongation outliers above': [],\n",
       " 'Mean elongation outliers below': [0.3886203009958631],\n",
       " 'Std elongation outliers above': [0.2834936036526987],\n",
       " 'Std elongation outliers below': [],\n",
       " 'Mean boundedness outliers above': [0.1255226833639739, 0.1392440232509124],\n",
       " 'Mean boundedness outliers below': [0.0716722009141775, 0.0716722009141775],\n",
       " 'Std boundedness outliers above': [0.0857543487635561],\n",
       " 'Std boundedness outliers below': [],\n",
       " 'Mean fractal_dim outliers above': [1.6584011141443462],\n",
       " 'Mean fractal_dim outliers below': [],\n",
       " 'Std fractal_dim outliers above': [0.3386802263648941, 0.4391440355029329],\n",
       " 'Std fractal_dim outliers below': [],\n",
       " 'Mean trappedness outliers above': [-0.1894624683436171, -0.1852837254865552],\n",
       " 'Mean trappedness outliers below': [-0.2054650511325136, -0.2054650511325136],\n",
       " 'Std trappedness outliers above': [0.0251345970284492],\n",
       " 'Std trappedness outliers below': [],\n",
       " 'Mean efficiency outliers above': [],\n",
       " 'Mean efficiency outliers below': [],\n",
       " 'Std efficiency outliers above': [1.7437402158880242],\n",
       " 'Std efficiency outliers below': [],\n",
       " 'Mean straightness outliers above': [0.4966612161821235],\n",
       " 'Mean straightness outliers below': [],\n",
       " 'Std straightness outliers above': [0.2962590493626114],\n",
       " 'Std straightness outliers below': [],\n",
       " 'Mean MSD_ratio outliers above': [0.3186214015474514, 0.2067695905087817],\n",
       " 'Mean MSD_ratio outliers below': [-0.0261360514774693, -0.0261360514774693],\n",
       " 'Std MSD_ratio outliers above': [0.634753668311037],\n",
       " 'Std MSD_ratio outliers below': [0.0706128703950455, 0.0706128703950455],\n",
       " 'Mean frames outliers above': [],\n",
       " 'Mean frames outliers below': [],\n",
       " 'Std frames outliers above': [14.307126809776324, 14.307126809776324],\n",
       " 'Std frames outliers below': [],\n",
       " 'Mean X outliers above': [],\n",
       " 'Mean X outliers below': [],\n",
       " 'Std X outliers above': [45.9936337635501, 45.9936337635501],\n",
       " 'Std X outliers below': [24.41583230055704, 17.95470848283451],\n",
       " 'Mean Y outliers above': [],\n",
       " 'Mean Y outliers below': [],\n",
       " 'Std Y outliers above': [],\n",
       " 'Std Y outliers below': [],\n",
       " 'Mean Quality outliers above': [],\n",
       " 'Mean Quality outliers below': [],\n",
       " 'Std Quality outliers above': [],\n",
       " 'Std Quality outliers below': [],\n",
       " 'Mean Mean_Intensity outliers above': [],\n",
       " 'Mean Mean_Intensity outliers below': [],\n",
       " 'Std Mean_Intensity outliers above': [],\n",
       " 'Std Mean_Intensity outliers below': [],\n",
       " 'Mean SN_Ratio outliers above': [],\n",
       " 'Mean SN_Ratio outliers below': [],\n",
       " 'Std SN_Ratio outliers above': [],\n",
       " 'Std SN_Ratio outliers below': [],\n",
       " 'Mean Deff1 outliers above': [],\n",
       " 'Mean Deff1 outliers below': [],\n",
       " 'Std Deff1 outliers above': [42.77067934229942, 42.77067934229942],\n",
       " 'Std Deff1 outliers below': [],\n",
       " 'Mean Deff2 outliers above': [],\n",
       " 'Mean Deff2 outliers below': [],\n",
       " 'Std Deff2 outliers above': [],\n",
       " 'Std Deff2 outliers below': [],\n",
       " 'Mean angle_mean outliers above': [],\n",
       " 'Mean angle_mean outliers below': [],\n",
       " 'Std angle_mean outliers above': [],\n",
       " 'Std angle_mean outliers below': [],\n",
       " 'Mean angle_mag_mean outliers above': [],\n",
       " 'Mean angle_mag_mean outliers below': [43.70047011055786],\n",
       " 'Std angle_mag_mean outliers above': [],\n",
       " 'Std angle_mag_mean outliers below': [9.411969593545464],\n",
       " 'Mean angle_var outliers above': [3636.446951845467],\n",
       " 'Mean angle_var outliers below': [2313.4284025299494],\n",
       " 'Std angle_var outliers above': [1338.855261763426],\n",
       " 'Std angle_var outliers below': [],\n",
       " 'Mean convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean dist_tot outliers above': [],\n",
       " 'Mean dist_tot outliers below': [],\n",
       " 'Std dist_tot outliers above': [29786.41700017949, 29786.41700017949],\n",
       " 'Std dist_tot outliers below': [],\n",
       " 'Mean dist_net outliers above': [2472.8000114132897],\n",
       " 'Mean dist_net outliers below': [1786.9630661075576],\n",
       " 'Std dist_net outliers above': [],\n",
       " 'Std dist_net outliers below': [],\n",
       " 'Mean progression outliers above': [],\n",
       " 'Mean progression outliers below': [],\n",
       " 'Std progression outliers above': [],\n",
       " 'Std progression outliers below': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_outliers(dummyFeatures_df1, \"all_features\", \"IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e60c235a-ce8a-4b69-8ec8-24fc96dd73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the multiplier you want to use: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Track_ID outliers above': [],\n",
       " 'Track_ID outliers below': [],\n",
       " 'alpha outliers above': [],\n",
       " 'alpha outliers below': [],\n",
       " 'D_fit outliers above': [],\n",
       " 'D_fit outliers below': [],\n",
       " 'kurtosis outliers above': [],\n",
       " 'kurtosis outliers below': [],\n",
       " 'asymmetry1 outliers above': [],\n",
       " 'asymmetry1 outliers below': [],\n",
       " 'asymmetry2 outliers above': [],\n",
       " 'asymmetry2 outliers below': [],\n",
       " 'asymmetry3 outliers above': [],\n",
       " 'asymmetry3 outliers below': [],\n",
       " 'AR outliers above': [],\n",
       " 'AR outliers below': [],\n",
       " 'elongation outliers above': [],\n",
       " 'elongation outliers below': [],\n",
       " 'boundedness outliers above': [],\n",
       " 'boundedness outliers below': [],\n",
       " 'fractal_dim outliers above': [],\n",
       " 'fractal_dim outliers below': [],\n",
       " 'trappedness outliers above': [],\n",
       " 'trappedness outliers below': [],\n",
       " 'efficiency outliers above': [],\n",
       " 'efficiency outliers below': [],\n",
       " 'straightness outliers above': [],\n",
       " 'straightness outliers below': [],\n",
       " 'MSD_ratio outliers above': [],\n",
       " 'MSD_ratio outliers below': [],\n",
       " 'frames outliers above': [],\n",
       " 'frames outliers below': [],\n",
       " 'X outliers above': [],\n",
       " 'X outliers below': [],\n",
       " 'Y outliers above': [],\n",
       " 'Y outliers below': [],\n",
       " 'Quality outliers above': [],\n",
       " 'Quality outliers below': [],\n",
       " 'Mean_Intensity outliers above': [],\n",
       " 'Mean_Intensity outliers below': [],\n",
       " 'SN_Ratio outliers above': [],\n",
       " 'SN_Ratio outliers below': [],\n",
       " 'Deff1 outliers above': [],\n",
       " 'Deff1 outliers below': [],\n",
       " 'Deff2 outliers above': [],\n",
       " 'Deff2 outliers below': [],\n",
       " 'angle_mean outliers above': [],\n",
       " 'angle_mean outliers below': [],\n",
       " 'angle_mag_mean outliers above': [],\n",
       " 'angle_mag_mean outliers below': [],\n",
       " 'angle_var outliers above': [],\n",
       " 'angle_var outliers below': [],\n",
       " 'convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'dist_tot outliers above': [],\n",
       " 'dist_tot outliers below': [],\n",
       " 'dist_net outliers above': [],\n",
       " 'dist_net outliers below': [],\n",
       " 'progression outliers above': [],\n",
       " 'progression outliers below': [],\n",
       " 'Mean alpha outliers above': [],\n",
       " 'Mean alpha outliers below': [],\n",
       " 'Std alpha outliers above': [],\n",
       " 'Std alpha outliers below': [],\n",
       " 'Mean D_fit outliers above': [],\n",
       " 'Mean D_fit outliers below': [],\n",
       " 'Std D_fit outliers above': [],\n",
       " 'Std D_fit outliers below': [],\n",
       " 'Mean kurtosis outliers above': [],\n",
       " 'Mean kurtosis outliers below': [],\n",
       " 'Std kurtosis outliers above': [],\n",
       " 'Std kurtosis outliers below': [],\n",
       " 'Mean asymmetry1 outliers above': [],\n",
       " 'Mean asymmetry1 outliers below': [],\n",
       " 'Std asymmetry1 outliers above': [],\n",
       " 'Std asymmetry1 outliers below': [],\n",
       " 'Mean asymmetry2 outliers above': [],\n",
       " 'Mean asymmetry2 outliers below': [],\n",
       " 'Std asymmetry2 outliers above': [],\n",
       " 'Std asymmetry2 outliers below': [],\n",
       " 'Mean asymmetry3 outliers above': [],\n",
       " 'Mean asymmetry3 outliers below': [],\n",
       " 'Std asymmetry3 outliers above': [],\n",
       " 'Std asymmetry3 outliers below': [],\n",
       " 'Mean AR outliers above': [],\n",
       " 'Mean AR outliers below': [],\n",
       " 'Std AR outliers above': [],\n",
       " 'Std AR outliers below': [],\n",
       " 'Mean elongation outliers above': [],\n",
       " 'Mean elongation outliers below': [],\n",
       " 'Std elongation outliers above': [],\n",
       " 'Std elongation outliers below': [],\n",
       " 'Mean boundedness outliers above': [],\n",
       " 'Mean boundedness outliers below': [],\n",
       " 'Std boundedness outliers above': [],\n",
       " 'Std boundedness outliers below': [],\n",
       " 'Mean fractal_dim outliers above': [],\n",
       " 'Mean fractal_dim outliers below': [],\n",
       " 'Std fractal_dim outliers above': [],\n",
       " 'Std fractal_dim outliers below': [],\n",
       " 'Mean trappedness outliers above': [],\n",
       " 'Mean trappedness outliers below': [],\n",
       " 'Std trappedness outliers above': [],\n",
       " 'Std trappedness outliers below': [],\n",
       " 'Mean efficiency outliers above': [],\n",
       " 'Mean efficiency outliers below': [],\n",
       " 'Std efficiency outliers above': [],\n",
       " 'Std efficiency outliers below': [],\n",
       " 'Mean straightness outliers above': [],\n",
       " 'Mean straightness outliers below': [],\n",
       " 'Std straightness outliers above': [],\n",
       " 'Std straightness outliers below': [],\n",
       " 'Mean MSD_ratio outliers above': [],\n",
       " 'Mean MSD_ratio outliers below': [],\n",
       " 'Std MSD_ratio outliers above': [],\n",
       " 'Std MSD_ratio outliers below': [],\n",
       " 'Mean frames outliers above': [],\n",
       " 'Mean frames outliers below': [],\n",
       " 'Std frames outliers above': [],\n",
       " 'Std frames outliers below': [],\n",
       " 'Mean X outliers above': [],\n",
       " 'Mean X outliers below': [],\n",
       " 'Std X outliers above': [],\n",
       " 'Std X outliers below': [],\n",
       " 'Mean Y outliers above': [],\n",
       " 'Mean Y outliers below': [],\n",
       " 'Std Y outliers above': [],\n",
       " 'Std Y outliers below': [],\n",
       " 'Mean Quality outliers above': [],\n",
       " 'Mean Quality outliers below': [],\n",
       " 'Std Quality outliers above': [],\n",
       " 'Std Quality outliers below': [],\n",
       " 'Mean Mean_Intensity outliers above': [],\n",
       " 'Mean Mean_Intensity outliers below': [],\n",
       " 'Std Mean_Intensity outliers above': [],\n",
       " 'Std Mean_Intensity outliers below': [],\n",
       " 'Mean SN_Ratio outliers above': [],\n",
       " 'Mean SN_Ratio outliers below': [],\n",
       " 'Std SN_Ratio outliers above': [],\n",
       " 'Std SN_Ratio outliers below': [],\n",
       " 'Mean Deff1 outliers above': [],\n",
       " 'Mean Deff1 outliers below': [],\n",
       " 'Std Deff1 outliers above': [],\n",
       " 'Std Deff1 outliers below': [],\n",
       " 'Mean Deff2 outliers above': [],\n",
       " 'Mean Deff2 outliers below': [],\n",
       " 'Std Deff2 outliers above': [],\n",
       " 'Std Deff2 outliers below': [],\n",
       " 'Mean angle_mean outliers above': [],\n",
       " 'Mean angle_mean outliers below': [],\n",
       " 'Std angle_mean outliers above': [],\n",
       " 'Std angle_mean outliers below': [],\n",
       " 'Mean angle_mag_mean outliers above': [],\n",
       " 'Mean angle_mag_mean outliers below': [],\n",
       " 'Std angle_mag_mean outliers above': [],\n",
       " 'Std angle_mag_mean outliers below': [],\n",
       " 'Mean angle_var outliers above': [],\n",
       " 'Mean angle_var outliers below': [],\n",
       " 'Std angle_var outliers above': [],\n",
       " 'Std angle_var outliers below': [],\n",
       " 'Mean convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull_norm outliers above': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Std convex_hull_norm outliers below': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'Mean dist_tot outliers above': [],\n",
       " 'Mean dist_tot outliers below': [],\n",
       " 'Std dist_tot outliers above': [],\n",
       " 'Std dist_tot outliers below': [],\n",
       " 'Mean dist_net outliers above': [],\n",
       " 'Mean dist_net outliers below': [],\n",
       " 'Std dist_net outliers above': [],\n",
       " 'Std dist_net outliers below': [],\n",
       " 'Mean progression outliers above': [],\n",
       " 'Mean progression outliers below': [],\n",
       " 'Std progression outliers above': [],\n",
       " 'Std progression outliers below': []}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_outliers(dummyFeatures_df1, \"all_features\", \"STD multiplier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d5c9473-ed2a-4cca-8d9f-eb6eb4af8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering to identify what features might contribute to data quality\n",
    "def feature_clustering(dataframe, features):\n",
    "    \"\"\"\n",
    "    Simple clustering method to provide a tool in determining whether\n",
    "    certain features have high contribution to data quality.\n",
    "\n",
    "    To be implemented in V2. Planning to use scipy k means, or \n",
    "    sci-kit learn NearestNeighbors or DBSCAN\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "234a3c08-7032-4f9a-84e0-3952bb6076c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df_exp1 = pd.DataFrame([[-1,0,1],[1,0,-1],[0.5,0,0.5]], index=[\"A\",\"B\",\"C\"])\n",
    "df_exp2 = pd.DataFrame([[1,0,1],[-1,0,-1],[0,0,0]], index=[\"A\",\"B\",\"C\"])\n",
    "class TestCorrelation(unittest.TestCase):\n",
    "\n",
    "    def test_corr_rowi_rowj_right_type(self):\n",
    "        computed_correlation = corr_rowi_rowj(df_exp1.iloc[0],df_exp1.iloc[2])\n",
    "        assert isinstance(computed_correlation,(float,int)), \"Computed correlation is neither int nor float, it is %s\" % type(computed_correlation)\n",
    "\n",
    "    def test_for_row_of_0(self):\n",
    "        rowi = df_exp2.iloc[2]\n",
    "        if rowi.all() == False:\n",
    "            rowiPOP = rowi.pop(0)\n",
    "            assert rowiPOP.all(), \"Row is all 0, and .corr will not work\"\n",
    "\n",
    "    def test_corr_rowi_rowj_right_value(self):\n",
    "        computed_correlation = corr_rowi_rowj(df_exp2.iloc[1],df_exp2.iloc[0])\n",
    "        assert 0 <= abs(computed_correlation) <= 1.00, \"Something went wrong, and the correlation is outside [0,|1|]\"\n",
    "\n",
    "    def test_corr_rowi_vs_all_right_type(self):\n",
    "        computed_correlation = corr_rowi_vs_all(df_exp1.iloc[1],df_exp2)\n",
    "        assert isinstance(computed_correlation, list), \"Something went wrong, and the function did not return a list.\"\n",
    "\n",
    "    def test_corr_rowi_vs_all_row_of_0(self):\n",
    "        computed_correlation = corr_rowi_vs_all(df_exp1.iloc[1],df_exp2)\n",
    "        compPOP = computed_correlation.pop(0)\n",
    "        assert compPOP.all == True, \"There was a row of zeros that resulted in NaN correlation values\"\n",
    "\n",
    "    def test_corr_rowi_vs_all_work_across_df(self):\n",
    "        corr1 = corr_rowi_vs_all(df_exp1.iloc[1],df_exp2)\n",
    "        corr2 = corr_rowi_vs_all(df_exp1.iloc[1],df_exp1)\n",
    "        assert type(corr1) == type(corr2), \"Did not work across dataframes\"\n",
    "\n",
    "    def test_pairwise_correlation_right_type(self):\n",
    "        computed_correlation = pairwise_correlation(df_exp1)\n",
    "        assert isinstance(computed_correlation, pd.DataFrame), \"Something went wrong, and the function did not return a DataFrame.\"\n",
    "\n",
    "    def test_pairwise_correlation_row_of_0_NA(self):\n",
    "        computed_correlation = pairwise_correlation(df_exp2)\n",
    "        corrNoNA = computed_correlation.dropna()\n",
    "        print(corrNoNA)\n",
    "        assert corrNoNA.empty == False, \"There was a row of 0, which .corr did not handle\"\n",
    "\n",
    "    def test_pairwise_correlation_right_shape(self):\n",
    "        computed_correlation = pairwise_correlation(df_exp1)\n",
    "        assert computed_correlation.shape == df_exp1.shape, \"Function resulted in different sized dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af2d06e9-dc9a-4168-b7be-dc94e0c52e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "dummy1 = pd.DataFrame([[-1,0,1,1,0],[1,0,-1,0,1],[0.5,0.5,0.5,0,7]], columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "dummy_stats = feature_descriptive_statistics(dummy1,[\"B\"])\n",
    "print(dummy_stats.iloc[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "681d25c5-3f34-4f3b-bfd2-d0291c820d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A outliers above': [], 'A outliers below': [-1.0], 'B outliers above': [0.5], 'B outliers below': [], 'C outliers above': [], 'C outliers below': [-1.0], 'D outliers above': [1.0], 'D outliers below': [], 'E outliers above': [7.0], 'E outliers below': []}\n"
     ]
    }
   ],
   "source": [
    "print(feature_outliers(dummy1,\"all_features\",\"IQR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf186bae-036b-4c74-bdd7-141ceaff4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "class TestStatistics(unittest.TestCase):\n",
    "    dummy_df1 = pd.DataFrame([[-1,0,1,0,0],[1,0,-1,0,1],[0.5,0.5,0.5,0,7]], columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "    dummy_df2 = pd.DataFrame([[1,0,1,2,1],[-1,0,-1,0,2],[0,0,0,1,30]], columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "    dummy_dict = {\"dummy_df1\": dummy_df1, \"dummy_df2\": dummy_df2}\n",
    "    dummy_list = [\"dummy_df1\", \"dummy_df2\"]\n",
    "    \n",
    "    def test_feature_descriptive_statistics_output1(self):\n",
    "        stats_df = feature_descriptive_statistics(dummy_df1,[\"A\"])\n",
    "        self.assertTrue(isinstance(stats_df,pd.DataFrame))\n",
    "\n",
    "    def test_feature_descriptive_statistics_output2(self):\n",
    "        stats_df = feature_descriptive_statistics(dummy_df1,\"all_features\")\n",
    "        self.assertTrue(isinstance(stats_df,pd.DataFrame))\n",
    "\n",
    "    def test_feature_descriptive_statistics_output3(self):\n",
    "        stats_df = feature_descriptive_statistics(dummy_df1,[\"B\"])\n",
    "        self.assertTrue(isinstance(stats_df.iloc[0].dtype,float))\n",
    "\n",
    "    def test_feature_descriptive_statistics_output4(self):\n",
    "        stats_df = feature_descriptive_statistics(dummer_df1,[\"A\"])\n",
    "        self.assrtTrue(np.isclose(stats_df[\"mean\"].iloc[0],0))\n",
    "\n",
    "    def test_multi_df_feat_descriptive_statistics_output1(self):\n",
    "        stats_dict = (dummy_dict,\"all_features\")\n",
    "        self.assertTrue(isintance(stats_dict,dict))\n",
    "\n",
    "    def test_multi_df_feat_descriptive_statistics_output2(self):\n",
    "        stats_dict = (dummy_dict,[\"C\"])\n",
    "        self.assertTrue(isintance(stats_dict,dict))\n",
    "\n",
    "    def test_multi_df_feat_descriptive_statistics_output3(self):\n",
    "        stats_dict = (dummy_dict,\"all_features\")\n",
    "        self.assertTrue(isintance(stats_dict[\"dummy_df2\"],pd.DataFrame))\n",
    "\n",
    "    def test_feature_outliers_output1(self):\n",
    "        outliers_list = feature_outliers(dummy_df1,\"all_features\")\n",
    "        self.assertTrue(isinstance(outliers_list,dict))\n",
    "\n",
    "    def test_feature_outliers_output2(self):\n",
    "        outliers_list = feature_outliers(dummy_df1,[\"A\",\"B\"])\n",
    "        self.assertTrue(isinstance(outliers_list,dict))\n",
    "\n",
    "    def test_feature_outliers_output3(self):\n",
    "        outliers_list = feature_outliers(dummy_df1,\"all_features\")\n",
    "        self.assertTrue(isinstance(outliers_list[\"A\"],list))\n",
    "\n",
    "    def test_feature_outliers_output4(self):\n",
    "        outliers_list = feature_outliers(dummy_df1,\"all_features\",\"IQR\")\n",
    "        self.assertTrue(np.isclose(outliers_list[\"E outliers above\"],7))\n",
    "\n",
    "    def test_feature_clustering(self):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
